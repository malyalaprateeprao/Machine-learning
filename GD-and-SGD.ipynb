{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "78066d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e5443c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change the code in this cell\n",
    "true_slope = 15\n",
    "true_intercept = 2.4\n",
    "input_var = np.arange(0.0,100.0)\n",
    "output_var = true_slope * input_var + true_intercept + 300.0 * np.random.rand(len(input_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "29186057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do not change the code in this cell\n",
    "plt.figure()\n",
    "plt.scatter(input_var, output_var)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "0f776e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(ip, op, params):\n",
    "    \"\"\"\n",
    "    Cost function in linear regression where the cost is calculated\n",
    "    ip: input variables\n",
    "    op: output variables\n",
    "    params: corresponding parameters\n",
    "    Returns cost\n",
    "    \"\"\"\n",
    "    num_samples = len(ip)\n",
    "    cost_sum = 0.0\n",
    "    for x,y in zip(ip, op):\n",
    "        y_hat = np.dot(params, np.array([1.0, x]))\n",
    "        cost_sum += (y_hat - y) ** 2\n",
    "    \n",
    "    cost = cost_sum / (num_samples)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "8078bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_using_batch_gradient_descent(ip, op, params, alpha, max_iter):\n",
    "    \"\"\"\n",
    "    Compute the params for linear regression using batch gradient descent\n",
    "    ip: input variables\n",
    "    op: output variables\n",
    "    params: corresponding parameters\n",
    "    alpha: learning rate\n",
    "    max_iter: maximum number of iterations\n",
    "    Returns parameters, cost, params_store\n",
    "    \"\"\" \n",
    "    # initialize iteration, number of samples, cost and parameter array\n",
    "    iteration = 0\n",
    "    num_samples = len(ip)\n",
    "    cost = np.zeros(max_iter)\n",
    "    params_store = np.zeros([2, max_iter])\n",
    "    \n",
    "    # Compute the cost and store the params for the corresponding cost\n",
    "    while iteration < max_iter:\n",
    "        cost[iteration] = compute_cost(ip, op, params)\n",
    "        params_store[:, iteration] = params\n",
    "        \n",
    "        print('--------------------------')\n",
    "        print(f'iteration: {iteration}')\n",
    "        print(f'cost: {cost[iteration]}')\n",
    "        \n",
    "        # Apply batch gradient descent\n",
    "        grad0, grad1 = 0, 0\n",
    "        for j in range(len(ip)):    \n",
    "            grad0 = grad0 + (op[j] - (params[0] + params[1]*ip[j]))\n",
    "            grad1 = grad1 + (op[j] - (params[0] + params[1]*ip[j])) * ip[j]\n",
    "        \n",
    "        params[0] = params[0] - alpha*(-2/len(ip))*grad0\n",
    "        params[1] = params[1] - alpha*(-2/len(ip))*grad1\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        #None\n",
    "    \n",
    "    return params, cost, params_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "49635b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "iteration: 0\n",
      "cost: 13360866.288642395\n",
      "--------------------------\n",
      "iteration: 1\n",
      "cost: 433766165.0251093\n",
      "--------------------------\n",
      "iteration: 2\n",
      "cost: 14092969053.919186\n",
      "--------------------------\n",
      "iteration: 3\n",
      "cost: 457888093314.1717\n",
      "--------------------------\n",
      "iteration: 4\n",
      "cost: 14877039332361.938\n",
      "--------------------------\n",
      "iteration: 5\n",
      "cost: 483363309431052.8\n",
      "--------------------------\n",
      "iteration: 6\n",
      "cost: 1.5704743655075946e+16\n",
      "--------------------------\n",
      "iteration: 7\n",
      "cost: 5.10255885096158e+17\n",
      "--------------------------\n",
      "iteration: 8\n",
      "cost: 1.6578498445676806e+19\n",
      "--------------------------\n",
      "iteration: 9\n",
      "cost: 5.386446658258901e+20\n",
      "--------------------------\n",
      "iteration: 10\n",
      "cost: 1.7500865773422604e+22\n",
      "--------------------------\n",
      "iteration: 11\n",
      "cost: 5.6861289501445787e+23\n",
      "--------------------------\n",
      "iteration: 12\n",
      "cost: 1.8474550262977757e+25\n",
      "--------------------------\n",
      "iteration: 13\n",
      "cost: 6.0024844742680896e+26\n",
      "--------------------------\n",
      "iteration: 14\n",
      "cost: 1.9502407014492671e+28\n",
      "--------------------------\n",
      "iteration: 15\n",
      "cost: 6.336440868600666e+29\n",
      "--------------------------\n",
      "iteration: 16\n",
      "cost: 2.0587449975500986e+31\n",
      "--------------------------\n",
      "iteration: 17\n",
      "cost: 6.688977381514748e+32\n",
      "--------------------------\n",
      "iteration: 18\n",
      "cost: 2.1732860778609955e+34\n",
      "--------------------------\n",
      "iteration: 19\n",
      "cost: 7.061127743198973e+35\n",
      "--------------------------\n",
      "iteration: 20\n",
      "cost: 2.29419980708878e+37\n",
      "--------------------------\n",
      "iteration: 21\n",
      "cost: 7.45398319682811e+38\n",
      "--------------------------\n",
      "iteration: 22\n",
      "cost: 2.4218407362304177e+40\n",
      "--------------------------\n",
      "iteration: 23\n",
      "cost: 7.868695698376359e+41\n",
      "--------------------------\n",
      "iteration: 24\n",
      "cost: 2.556583142210214e+43\n",
      "--------------------------\n",
      "iteration: 25\n",
      "cost: 8.306481294456626e+44\n",
      "--------------------------\n",
      "iteration: 26\n",
      "cost: 2.698822125358615e+46\n",
      "--------------------------\n",
      "iteration: 27\n",
      "cost: 8.768623688090361e+47\n",
      "--------------------------\n",
      "iteration: 28\n",
      "cost: 2.8489747679507686e+49\n",
      "--------------------------\n",
      "iteration: 29\n",
      "cost: 9.256478002864077e+50\n",
      "--------------------------\n",
      "iteration: 30\n",
      "cost: 3.0074813572019317e+52\n",
      "--------------------------\n",
      "iteration: 31\n",
      "cost: 9.771474756509515e+53\n",
      "--------------------------\n",
      "iteration: 32\n",
      "cost: 3.174806676305913e+55\n",
      "--------------------------\n",
      "iteration: 33\n",
      "cost: 1.0315124055559734e+57\n",
      "--------------------------\n",
      "iteration: 34\n",
      "cost: 3.351441367302162e+58\n",
      "--------------------------\n",
      "iteration: 35\n",
      "cost: 1.0889020023380294e+60\n",
      "--------------------------\n",
      "iteration: 36\n",
      "cost: 3.5379033697678497e+61\n",
      "--------------------------\n",
      "iteration: 37\n",
      "cost: 1.1494845474560094e+63\n",
      "--------------------------\n",
      "iteration: 38\n",
      "cost: 3.7347394395535656e+64\n",
      "--------------------------\n",
      "iteration: 39\n",
      "cost: 1.213437684936839e+66\n",
      "--------------------------\n",
      "iteration: 40\n",
      "cost: 3.942526752015884e+67\n",
      "--------------------------\n",
      "iteration: 41\n",
      "cost: 1.2809489422746898e+69\n",
      "--------------------------\n",
      "iteration: 42\n",
      "cost: 4.161874594447992e+70\n",
      "--------------------------\n",
      "iteration: 43\n",
      "cost: 1.3522162803111327e+72\n",
      "--------------------------\n",
      "iteration: 44\n",
      "cost: 4.3934261526709953e+73\n",
      "--------------------------\n",
      "iteration: 45\n",
      "cost: 1.4274486737086315e+75\n",
      "--------------------------\n",
      "iteration: 46\n",
      "cost: 4.637860397024678e+76\n",
      "--------------------------\n",
      "iteration: 47\n",
      "cost: 1.5068667237194444e+78\n",
      "--------------------------\n",
      "iteration: 48\n",
      "cost: 4.8958940732878836e+79\n",
      "--------------------------\n",
      "iteration: 49\n",
      "cost: 1.5907033050467878e+81\n",
      "--------------------------\n",
      "iteration: 50\n",
      "cost: 5.168283804366505e+82\n",
      "--------------------------\n",
      "iteration: 51\n",
      "cost: 1.6792042486949783e+84\n",
      "--------------------------\n",
      "iteration: 52\n",
      "cost: 5.455828308911707e+85\n",
      "--------------------------\n",
      "iteration: 53\n",
      "cost: 1.7726290628108846e+87\n",
      "--------------------------\n",
      "iteration: 54\n",
      "cost: 5.759370743374045e+88\n",
      "--------------------------\n",
      "iteration: 55\n",
      "cost: 1.8712516936303715e+90\n",
      "--------------------------\n",
      "iteration: 56\n",
      "cost: 6.0798011743609036e+91\n",
      "--------------------------\n",
      "iteration: 57\n",
      "cost: 1.975361328761033e+93\n",
      "--------------------------\n",
      "iteration: 58\n",
      "cost: 6.4180591885469475e+94\n",
      "--------------------------\n",
      "iteration: 59\n",
      "cost: 2.0852632451566555e+96\n",
      "--------------------------\n",
      "iteration: 60\n",
      "cost: 6.775136647790442e+97\n",
      "--------------------------\n",
      "iteration: 61\n",
      "cost: 2.2012797042698894e+99\n",
      "--------------------------\n",
      "iteration: 62\n",
      "cost: 7.152080597534258e+100\n",
      "--------------------------\n",
      "iteration: 63\n",
      "cost: 2.3237508970079703e+102\n",
      "--------------------------\n",
      "iteration: 64\n",
      "cost: 7.549996337019728e+103\n",
      "--------------------------\n",
      "iteration: 65\n",
      "cost: 2.4530359412623327e+105\n",
      "--------------------------\n",
      "iteration: 66\n",
      "cost: 7.970050660316035e+106\n",
      "--------------------------\n",
      "iteration: 67\n",
      "cost: 2.5895139349371206e+108\n",
      "--------------------------\n",
      "iteration: 68\n",
      "cost: 8.413475277668608e+109\n",
      "--------------------------\n",
      "iteration: 69\n",
      "cost: 2.7335850675644146e+111\n",
      "--------------------------\n",
      "iteration: 70\n",
      "cost: 8.881570427198996e+112\n",
      "--------------------------\n",
      "iteration: 71\n",
      "cost: 2.885671793765647e+114\n",
      "--------------------------\n",
      "iteration: 72\n",
      "cost: 9.375708687546589e+115\n",
      "--------------------------\n",
      "iteration: 73\n",
      "cost: 3.0462200720001645e+117\n",
      "--------------------------\n",
      "iteration: 74\n",
      "cost: 9.897339002631627e+118\n",
      "--------------------------\n",
      "iteration: 75\n",
      "cost: 3.215700672233241e+120\n",
      "--------------------------\n",
      "iteration: 76\n",
      "cost: 1.044799093034178e+122\n",
      "--------------------------\n",
      "iteration: 77\n",
      "cost: 3.3946105563579773e+123\n",
      "--------------------------\n",
      "iteration: 78\n",
      "cost: 1.1029279127599755e+125\n",
      "--------------------------\n",
      "iteration: 79\n",
      "cost: 3.5834743354188635e+126\n",
      "--------------------------\n",
      "iteration: 80\n",
      "cost: 1.1642908084964073e+128\n",
      "--------------------------\n",
      "iteration: 81\n",
      "cost: 3.78284580790996e+129\n",
      "--------------------------\n",
      "iteration: 82\n",
      "cost: 1.2290677124645634e+131\n",
      "--------------------------\n",
      "iteration: 83\n",
      "cost: 3.993309583658372e+132\n",
      "--------------------------\n",
      "iteration: 84\n",
      "cost: 1.2974485676595775e+134\n",
      "--------------------------\n",
      "iteration: 85\n",
      "cost: 4.215482798054705e+135\n",
      "--------------------------\n",
      "iteration: 86\n",
      "cost: 1.3696338848136673e+137\n",
      "--------------------------\n",
      "iteration: 87\n",
      "cost: 4.4500169216570824e+138\n",
      "--------------------------\n",
      "iteration: 88\n",
      "cost: 1.4458353303465787e+140\n",
      "--------------------------\n",
      "iteration: 89\n",
      "cost: 4.6975996704748883e+141\n",
      "--------------------------\n",
      "iteration: 90\n",
      "cost: 1.5262763470274356e+143\n",
      "--------------------------\n",
      "iteration: 91\n",
      "cost: 4.958957022533837e+144\n",
      "--------------------------\n",
      "iteration: 92\n",
      "cost: 1.6111928091679757e+146\n",
      "--------------------------\n",
      "iteration: 93\n",
      "cost: 5.2348553466353e+147\n",
      "--------------------------\n",
      "iteration: 94\n",
      "cost: 1.700833714268347e+149\n",
      "--------------------------\n",
      "iteration: 95\n",
      "cost: 5.526103649552088e+150\n",
      "--------------------------\n",
      "iteration: 96\n",
      "cost: 1.795461913143544e+152\n",
      "--------------------------\n",
      "iteration: 97\n",
      "cost: 5.833555948250028e+153\n",
      "--------------------------\n",
      "iteration: 98\n",
      "cost: 1.8953548806714567e+155\n",
      "--------------------------\n",
      "iteration: 99\n",
      "cost: 6.158113774091371e+156\n"
     ]
    }
   ],
   "source": [
    "# Do not change the code in this cell\n",
    "# Training the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_var, output_var, test_size=0.20)\n",
    "\n",
    "params_0 = np.array([20.0, 80.0])\n",
    "\n",
    "alpha_batch = 1e-3\n",
    "max_iter = 100\n",
    "params_hat_batch, cost_batch, params_store_batch =\\\n",
    "    linear_regression_using_batch_gradient_descent(x_train, y_train, params_0, alpha_batch, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "fe85d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_stoch_gradient_descent(ip, op, params, alpha):\n",
    "    \"\"\"\n",
    "    Compute the params for linear regression using stochastic gradient descent\n",
    "    ip: input variables\n",
    "    op: output variables\n",
    "    params: corresponding parameters\n",
    "    alpha: learning rate\n",
    "    Returns parameters, cost, params_store\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize iteration, number of samples, cost and parameter array\n",
    "    num_samples = len(input_var)\n",
    "    cost = np.zeros(num_samples)\n",
    "    params_store = np.zeros([2, num_samples])\n",
    "    \n",
    "    i = 0\n",
    "    # Compute the cost and store the params for the corresponding cost\n",
    "    for x,y in zip(input_var, output_var):\n",
    "        cost[i] = compute_cost(input_var, output_var, params)\n",
    "        params_store[:, i] = params\n",
    "        \n",
    "        print('--------------------------')\n",
    "        print(f'iteration: {i}')\n",
    "        print(f'cost: {cost[i]}')\n",
    "        \n",
    "        # Apply stochastic gradient descent\n",
    "        index = np.random.randint(0, len(ip), 1) #random sample\n",
    "        x = np.take(ip, index)\n",
    "        y = np.take(op, index)\n",
    "        params[0] = params[0] - alpha * (-2/len(ip)) * (y - (params[0] + params[1] * x))\n",
    "        params[1] = params[1] - alpha * (-2/len(ip)) * (y - (params[0] + params[1] * x)) * x\n",
    "        \n",
    "        i = i + 1;\n",
    "        #None\n",
    "            \n",
    "    return params, cost, params_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "b7c5e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "iteration: 0\n",
      "cost: 13069770.405666567\n",
      "--------------------------\n",
      "iteration: 1\n",
      "cost: 9854245.798537338\n",
      "--------------------------\n",
      "iteration: 2\n",
      "cost: 8513323.307329785\n",
      "--------------------------\n",
      "iteration: 3\n",
      "cost: 8134985.11985709\n",
      "--------------------------\n",
      "iteration: 4\n",
      "cost: 7848387.389165546\n",
      "--------------------------\n",
      "iteration: 5\n",
      "cost: 7842829.749375889\n",
      "--------------------------\n",
      "iteration: 6\n",
      "cost: 7352503.259097794\n",
      "--------------------------\n",
      "iteration: 7\n",
      "cost: 4479214.726967116\n",
      "--------------------------\n",
      "iteration: 8\n",
      "cost: 4459260.001009515\n",
      "--------------------------\n",
      "iteration: 9\n",
      "cost: 4390781.47769938\n",
      "--------------------------\n",
      "iteration: 10\n",
      "cost: 3085239.8874102193\n",
      "--------------------------\n",
      "iteration: 11\n",
      "cost: 2475829.5553899296\n",
      "--------------------------\n",
      "iteration: 12\n",
      "cost: 1752853.556724417\n",
      "--------------------------\n",
      "iteration: 13\n",
      "cost: 1749219.0861028135\n",
      "--------------------------\n",
      "iteration: 14\n",
      "cost: 1689641.1827314473\n",
      "--------------------------\n",
      "iteration: 15\n",
      "cost: 1486187.5254975124\n",
      "--------------------------\n",
      "iteration: 16\n",
      "cost: 1477514.9036636408\n",
      "--------------------------\n",
      "iteration: 17\n",
      "cost: 854877.6652721583\n",
      "--------------------------\n",
      "iteration: 18\n",
      "cost: 707386.4891247004\n",
      "--------------------------\n",
      "iteration: 19\n",
      "cost: 676421.3355361371\n",
      "--------------------------\n",
      "iteration: 20\n",
      "cost: 676424.6063337306\n",
      "--------------------------\n",
      "iteration: 21\n",
      "cost: 676427.8770613227\n",
      "--------------------------\n",
      "iteration: 22\n",
      "cost: 605402.2660446204\n",
      "--------------------------\n",
      "iteration: 23\n",
      "cost: 356396.2606810815\n",
      "--------------------------\n",
      "iteration: 24\n",
      "cost: 316264.5574392028\n",
      "--------------------------\n",
      "iteration: 25\n",
      "cost: 215090.32916869596\n",
      "--------------------------\n",
      "iteration: 26\n",
      "cost: 162959.0765127977\n",
      "--------------------------\n",
      "iteration: 27\n",
      "cost: 164990.45233276393\n",
      "--------------------------\n",
      "iteration: 28\n",
      "cost: 153173.6593657359\n",
      "--------------------------\n",
      "iteration: 29\n",
      "cost: 131918.04854432223\n",
      "--------------------------\n",
      "iteration: 30\n",
      "cost: 91898.5291457235\n",
      "--------------------------\n",
      "iteration: 31\n",
      "cost: 87168.23266996426\n",
      "--------------------------\n",
      "iteration: 32\n",
      "cost: 83082.46293482216\n",
      "--------------------------\n",
      "iteration: 33\n",
      "cost: 76777.56508049996\n",
      "--------------------------\n",
      "iteration: 34\n",
      "cost: 58331.531758587\n",
      "--------------------------\n",
      "iteration: 35\n",
      "cost: 58708.9373308098\n",
      "--------------------------\n",
      "iteration: 36\n",
      "cost: 52046.457424002205\n",
      "--------------------------\n",
      "iteration: 37\n",
      "cost: 52422.09973727598\n",
      "--------------------------\n",
      "iteration: 38\n",
      "cost: 29562.23361476625\n",
      "--------------------------\n",
      "iteration: 39\n",
      "cost: 25505.768853985333\n",
      "--------------------------\n",
      "iteration: 40\n",
      "cost: 15845.243592704186\n",
      "--------------------------\n",
      "iteration: 41\n",
      "cost: 16154.178361409002\n",
      "--------------------------\n",
      "iteration: 42\n",
      "cost: 15893.69043065641\n",
      "--------------------------\n",
      "iteration: 43\n",
      "cost: 13575.80244118029\n",
      "--------------------------\n",
      "iteration: 44\n",
      "cost: 13811.248583831706\n",
      "--------------------------\n",
      "iteration: 45\n",
      "cost: 11534.810688553336\n",
      "--------------------------\n",
      "iteration: 46\n",
      "cost: 11945.70109846843\n",
      "--------------------------\n",
      "iteration: 47\n",
      "cost: 12260.981058489902\n",
      "--------------------------\n",
      "iteration: 48\n",
      "cost: 13016.660535065452\n",
      "--------------------------\n",
      "iteration: 49\n",
      "cost: 12874.245862818345\n",
      "--------------------------\n",
      "iteration: 50\n",
      "cost: 12757.964429483167\n",
      "--------------------------\n",
      "iteration: 51\n",
      "cost: 11074.420482001262\n",
      "--------------------------\n",
      "iteration: 52\n",
      "cost: 11232.934204832714\n",
      "--------------------------\n",
      "iteration: 53\n",
      "cost: 11627.664240100303\n",
      "--------------------------\n",
      "iteration: 54\n",
      "cost: 10534.199483521727\n",
      "--------------------------\n",
      "iteration: 55\n",
      "cost: 10518.373459267856\n",
      "--------------------------\n",
      "iteration: 56\n",
      "cost: 10569.271398590254\n",
      "--------------------------\n",
      "iteration: 57\n",
      "cost: 10158.631240259143\n",
      "--------------------------\n",
      "iteration: 58\n",
      "cost: 10141.633223797811\n",
      "--------------------------\n",
      "iteration: 59\n",
      "cost: 10167.05147818899\n",
      "--------------------------\n",
      "iteration: 60\n",
      "cost: 10333.87084760841\n",
      "--------------------------\n",
      "iteration: 61\n",
      "cost: 10333.661070272003\n",
      "--------------------------\n",
      "iteration: 62\n",
      "cost: 10234.800978483743\n",
      "--------------------------\n",
      "iteration: 63\n",
      "cost: 10147.8715486066\n",
      "--------------------------\n",
      "iteration: 64\n",
      "cost: 10135.717665139833\n",
      "--------------------------\n",
      "iteration: 65\n",
      "cost: 10168.816409989546\n",
      "--------------------------\n",
      "iteration: 66\n",
      "cost: 10219.992477845175\n",
      "--------------------------\n",
      "iteration: 67\n",
      "cost: 10522.060369138775\n",
      "--------------------------\n",
      "iteration: 68\n",
      "cost: 10300.581370157373\n",
      "--------------------------\n",
      "iteration: 69\n",
      "cost: 10145.561906075767\n",
      "--------------------------\n",
      "iteration: 70\n",
      "cost: 10396.724850546228\n",
      "--------------------------\n",
      "iteration: 71\n",
      "cost: 10575.322683637316\n",
      "--------------------------\n",
      "iteration: 72\n",
      "cost: 10637.58843151009\n",
      "--------------------------\n",
      "iteration: 73\n",
      "cost: 10473.119938086664\n",
      "--------------------------\n",
      "iteration: 74\n",
      "cost: 10144.884306416396\n",
      "--------------------------\n",
      "iteration: 75\n",
      "cost: 10150.114212800641\n",
      "--------------------------\n",
      "iteration: 76\n",
      "cost: 10421.597572804318\n",
      "--------------------------\n",
      "iteration: 77\n",
      "cost: 10536.70756127939\n",
      "--------------------------\n",
      "iteration: 78\n",
      "cost: 10505.942382309968\n",
      "--------------------------\n",
      "iteration: 79\n",
      "cost: 10416.340166378577\n",
      "--------------------------\n",
      "iteration: 80\n",
      "cost: 10390.730440121006\n",
      "--------------------------\n",
      "iteration: 81\n",
      "cost: 10366.344126948852\n",
      "--------------------------\n",
      "iteration: 82\n",
      "cost: 10286.355987342009\n",
      "--------------------------\n",
      "iteration: 83\n",
      "cost: 10322.11838756079\n",
      "--------------------------\n",
      "iteration: 84\n",
      "cost: 10507.36408369129\n",
      "--------------------------\n",
      "iteration: 85\n",
      "cost: 10363.94280503553\n",
      "--------------------------\n",
      "iteration: 86\n",
      "cost: 10161.755469059824\n",
      "--------------------------\n",
      "iteration: 87\n",
      "cost: 10155.948814678852\n",
      "--------------------------\n",
      "iteration: 88\n",
      "cost: 10137.846663924041\n",
      "--------------------------\n",
      "iteration: 89\n",
      "cost: 10134.734178332348\n",
      "--------------------------\n",
      "iteration: 90\n",
      "cost: 10167.236663032243\n",
      "--------------------------\n",
      "iteration: 91\n",
      "cost: 10227.833830964995\n",
      "--------------------------\n",
      "iteration: 92\n",
      "cost: 10317.560254682841\n",
      "--------------------------\n",
      "iteration: 93\n",
      "cost: 10567.967218864034\n",
      "--------------------------\n",
      "iteration: 94\n",
      "cost: 10562.59953188256\n",
      "--------------------------\n",
      "iteration: 95\n",
      "cost: 10212.666672986361\n",
      "--------------------------\n",
      "iteration: 96\n",
      "cost: 10136.877493267037\n",
      "--------------------------\n",
      "iteration: 97\n",
      "cost: 10144.988783860004\n",
      "--------------------------\n",
      "iteration: 98\n",
      "cost: 10185.945775573526\n",
      "--------------------------\n",
      "iteration: 99\n",
      "cost: 10257.932491733216\n"
     ]
    }
   ],
   "source": [
    "# Do not change the code in this cell\n",
    "alpha = 1e-3\n",
    "params_0 = np.array([20.0, 80.0])\n",
    "params_hat, cost, params_store =\\\n",
    "lin_reg_stoch_gradient_descent(x_train, y_train, params_0, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "8bc1121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_batch 3450.418362135709\n",
      "RMSE_stochastic 89.14389898650074\n"
     ]
    }
   ],
   "source": [
    "# Calculate Root Mean Square error in batch gradient descent algorithm and stochastic gradient descent algorithm\n",
    "\n",
    "import math\n",
    "\n",
    "#batch gradient descent\n",
    "\n",
    "min_cost_index_batch = np.argmin(cost_batch)\n",
    "params0_batch, params1_batch = params_store_batch[0][min_cost_index_batch], params_store_batch[1][min_cost_index_batch]\n",
    "\n",
    "#print(params0_batch, params1_batch)\n",
    "\n",
    "MSE_batch = 0\n",
    "for j in range(len(x_test)):\n",
    "    y_pred = params0_batch + params1_batch*x_test[j]\n",
    "    MSE_batch = MSE_batch + (y_pred - y_test[j])**2\n",
    "    \n",
    "RMSE_batch = math.sqrt(MSE_batch/len(x_test))\n",
    "\n",
    "\n",
    "\n",
    "#stochastic gradient descent\n",
    "\n",
    "min_cost_index = np.argmin(cost)\n",
    "params0, params1 = params_store[0][min_cost_index], params_store[1][min_cost_index]\n",
    "\n",
    "#print(params0, params1)\n",
    "\n",
    "MSE = 0\n",
    "for j in range(len(x_test)):\n",
    "    y_pred = params0 + params1*x_test[j]\n",
    "    MSE = MSE + (y_pred - y_test[j])**2\n",
    "    \n",
    "RMSE = math.sqrt(MSE/len(x_test))\n",
    "\n",
    "\n",
    "print('RMSE_batch', RMSE_batch)\n",
    "print('RMSE_stochastic', RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "8d8f2464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min cost with BGD: 13360866.288642395\n",
      "min cost with SGD: 10134.734178332348\n"
     ]
    }
   ],
   "source": [
    "# Do not change the code in this cell\n",
    "plt.figure()\n",
    "plt.plot(np.arange(max_iter), cost_batch, 'r', label='batch')\n",
    "plt.plot(np.arange(len(cost)), cost, 'g', label='stochastic')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('normalized cost')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(f'min cost with BGD: {np.min(cost_batch)}')\n",
    "print(f'min cost with SGD: {np.min(cost)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "2023fdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor this type of data and learning rate, Stochastic Gradient descent works well, by observing the above results u can see the Root minimum square\\nerror value for stochastic gradient descent is far better than gradient descent.\\n\\nIf training data is too large, in each iteration if we want to train on that data it is time taking process so, instead we can use batch or stochastic \\ngradient descent which only trains on a random training data based on batch size which is very fast when we want to train on large data.\\n\\nObservations:\\n\\n1. here the data size is not that much big, but we are using a high learning rate in gradient descent, rather if we use very less\\n   learning rate and increase the number of iterations u will get a very less error value compared to stochastic gradient descent.\\n2. so by this observations we can say learning rate is the one which helps us to get the minimum error value, in above gradient descent\\n   if u change the learning rate to very low (<=0.00001) the RMSE value will decrease a lot.\\n3. And if u want further minimize the RSME value we need to increase the number of iterations.\\n4. here stochastic gradient descent worked well even with high learning rate because we use only one training sample and it starts \\n   improving itself right away from the first sample.\\n5. SGD often converges much faster compared to GD but the error function is not as well minimized as in the case of GD, but in most cases \\n   the close approximation that you get in SGD for the parameter values are enough because they reach the optimal values and keep oscillating there.\\n\\n\\n** So deciding good learning rate is important in Gradient descent **\\n\\n'"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which linear regression model do you think works best for this data? Explain in brief\n",
    "\n",
    "'''\n",
    "For this type of data and learning rate, Stochastic Gradient descent works well, by observing the above results u can see the Root minimum square\n",
    "error value for stochastic gradient descent is far better than gradient descent.\n",
    "\n",
    "If training data is too large, in each iteration if we want to train on that data it is time taking process so, instead we can use batch or stochastic \n",
    "gradient descent which only trains on a random training data based on batch size which is very fast when we want to train on large data.\n",
    "\n",
    "Observations:\n",
    "\n",
    "1. here the data size is not that much big, but we are using a high learning rate in gradient descent, rather if we use very less\n",
    "   learning rate and increase the number of iterations u will get a very less error value compared to stochastic gradient descent.\n",
    "2. so by this observations we can say learning rate is the one which helps us to get the minimum error value, in above gradient descent\n",
    "   if u change the learning rate to very low (<=0.00001) the RMSE value will decrease a lot.\n",
    "3. And if u want further minimize the RSME value we need to increase the number of iterations.\n",
    "4. here stochastic gradient descent worked well even with high learning rate because we use only one training sample and it starts \n",
    "   improving itself right away from the first sample.\n",
    "5. SGD often converges much faster compared to GD but the error function is not as well minimized as in the case of GD, but in most cases \n",
    "   the close approximation that you get in SGD for the parameter values are enough because they reach the optimal values and keep oscillating there.\n",
    "\n",
    "\n",
    "** So deciding good learning rate is important in Gradient descent **\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6790f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
