{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0259765",
   "metadata": {
    "id": "c0259765"
   },
   "source": [
    "# CS 6140 Machine Learning: Assignment - 2 (Total Points: 100)\n",
    "## Prof. Ahmad Uzair\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775045f",
   "metadata": {
    "id": "e775045f"
   },
   "source": [
    "## Question 1 - Naive Bayes Classification (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9372fb",
   "metadata": {
    "id": "ed9372fb"
   },
   "source": [
    "![Q1_1.png](attachment:Q1_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a43e9",
   "metadata": {
    "id": "0a5a43e9"
   },
   "source": [
    "![Q1_2.png](attachment:Q1_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98d11d",
   "metadata": {
    "id": "7c98d11d"
   },
   "source": [
    "## Question 2 - Classification Metrics (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb6759",
   "metadata": {
    "id": "1ffb6759"
   },
   "source": [
    "![Q2.png](attachment:Q2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca0ce4f",
   "metadata": {
    "id": "0ca0ce4f"
   },
   "source": [
    "## Question 3 -  Logistic Regression and Perceptron  (70 points)\n",
    "\n",
    " In this problem you will be applying logistic regression and perceptron to the breastcancer dataset for binary classification:\n",
    "\n",
    " **default of credit card clients**:  This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbee24d",
   "metadata": {
    "id": "fdbee24d"
   },
   "source": [
    "### Task\n",
    "- Prepare a normalized version of data. Use min-max normalization. \n",
    "- Train two logistic regression models using gradient descent with raw as well as normalized data. \n",
    "- Train two perceptron classifiers with raw as well as normalized data.\n",
    "- Compare training and test results of four models in terms of accuracy. \n",
    "\n",
    "Note:\n",
    "\n",
    "The skeleton code is only a guide. You can change the method definitions where necessary with appropriate comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d425c",
   "metadata": {
    "id": "4b7d425c"
   },
   "outputs": [],
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67fca1",
   "metadata": {
    "id": "6f67fca1"
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    ''' data: input features\n",
    "        labels: output features\n",
    "    '''\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2391d",
   "metadata": {
    "id": "2bb2391d"
   },
   "source": [
    "### 1) Implementation of sigmoid and cost function (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f982e9",
   "metadata": {
    "id": "10f982e9"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' return sigmoid'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0962e",
   "metadata": {
    "id": "f0b0962e"
   },
   "outputs": [],
   "source": [
    "## Implement the loss function for logistic regression\n",
    "\n",
    "def compute_cost(ip, op, params):\n",
    "    \"\"\"\n",
    "    Cost function in linear regression where the cost is calculated\n",
    "    ip: input variables\n",
    "    op: output variables\n",
    "    params: corresponding parameters\n",
    "    Returns cost\n",
    "    \"\"\"\n",
    "#     print (cost_sum)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced13867",
   "metadata": {
    "id": "ced13867"
   },
   "source": [
    "\n",
    "### 2)  Implement logistic regression using batch gradient descent and evaluation (20 points)\n",
    "Algorithm can be given as follows:\n",
    "\n",
    "```for j in 0 -> max_iteration: \n",
    "    for i in 0 -> m: \n",
    "        theta += (alpha / m) * (y[i] - h(x[i])) * x_bar\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb063fa6",
   "metadata": {
    "id": "cb063fa6"
   },
   "outputs": [],
   "source": [
    "def logistic_regression_using_batch_gradient_descent(ip, op, params, alpha, max_iter, batch_size = 1):\n",
    "    \"\"\"\n",
    "    Compute the params for logistic regression using batch gradient descent\n",
    "    ip: input variables\n",
    "    op: output variables\n",
    "    params: corresponding parameters\n",
    "    alpha: learning rate\n",
    "    max_iter: maximum number of iterations\n",
    "    Returns parameters, cost, params_store\n",
    "    \"\"\" \n",
    "    # initialize iteration, number of samples, cost and parameter array\n",
    "\n",
    "    \n",
    "    #batchify the data into mini-batches\n",
    "\n",
    "    \n",
    "    \n",
    "    # Compute the cost and store the params for the corresponding cost\n",
    "\n",
    "    \n",
    "    return params, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e26ce",
   "metadata": {
    "id": "3f5e26ce"
   },
   "source": [
    "### 3) Implementation of perceptron.(20 points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68380bd3",
   "metadata": {
    "id": "68380bd3"
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "# constructor \n",
    "    def __init__ (self):\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "# model\n",
    "\n",
    "    \n",
    "# fitting the model    \n",
    "    \n",
    "    \n",
    "    \n",
    "# predictor to predict on the data based on w "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84b7b4",
   "metadata": {
    "id": "1f84b7b4"
   },
   "source": [
    "### 4) Apply 80-20 split on data to prepare training and test sets. Report training and test results in terms of accuracy, precision and recall for both logistic regression and perceptron. (20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0d71e",
   "metadata": {
    "id": "cae0d71e"
   },
   "outputs": [],
   "source": [
    "# Sample training code cell change according to your variables and structure\n",
    "\n",
    "# Training the model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#reserve the test data, do not use them for cross-validation!\n",
    "\n",
    "data, labels = load_data(DATA_DIR)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.20)\n",
    "x_train = np.append(x_train, np.ones((x_train.shape[0],1)), axis=1)\n",
    "x_test = np.append(x_test, np.ones((x_test.shape[0],1)), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582ec4f",
   "metadata": {
    "id": "8582ec4f"
   },
   "outputs": [],
   "source": [
    "def evaluate(x_test, y_test,params):\n",
    "    '''return the accuracy scores'''\n",
    "\n",
    "    return acc\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CS6140-Assign_2_Summer22.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
